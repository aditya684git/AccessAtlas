# AccessAtlas Real-Image Training Pipeline

Complete production-ready machine learning pipeline for training accessibility tag classification models using real map tile images and metadata.

---

## ğŸ¯ Overview

This pipeline trains deep learning models to classify accessibility features (ramps, elevators, tactile paving, etc.) from map tile images combined with geospatial metadata.

**Features:**
- âœ… Multi-provider tile generation (OSM, Mapbox, Google)
- âœ… Robust data preprocessing with stratified splits
- âœ… Multiple model architectures (Custom CNN, ResNet, EfficientNet, MobileNet)
- âœ… Transfer learning with pretrained ImageNet weights
- âœ… Advanced training features (mixed precision, gradient accumulation, early stopping)
- âœ… Experiment tracking (W&B support)
- âœ… Model export (ONNX, TorchScript, CoreML, TFLite)
- âœ… Comprehensive evaluation and error analysis

---

## ğŸ“ Project Structure

```
AccessAtlas/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/              # Map tile images
â”‚   â”œâ”€â”€ tags.csv             # Raw dataset
â”‚   â”œâ”€â”€ tags_train.csv       # Training split
â”‚   â”œâ”€â”€ tags_val.csv         # Validation split
â”‚   â”œâ”€â”€ tags_test.csv        # Test split
â”‚   â”œâ”€â”€ preprocessing_metadata.json
â”‚   â””â”€â”€ preprocess.py        # Data preprocessing script
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ baseline/
â”‚       â”œâ”€â”€ model.py         # Original baseline model
â”‚       â”œâ”€â”€ model_v2.py      # Production model with transfer learning
â”‚       â”œâ”€â”€ dataset.py       # PyTorch dataset loaders
â”‚       â”œâ”€â”€ train.py         # Basic training script
â”‚       â”œâ”€â”€ evaluate.py      # Evaluation script
â”‚       â”œâ”€â”€ predict.py       # Inference script
â”‚       â”œâ”€â”€ config.yaml      # Configuration file
â”‚       â”œâ”€â”€ checkpoints/     # Saved models
â”‚       â”œâ”€â”€ logs/            # Training logs
â”‚       â””â”€â”€ errors/          # Error analysis
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_tiles.py   # Download map tiles
â”‚   â”œâ”€â”€ train_pipeline.py   # Advanced training pipeline
â”‚   â””â”€â”€ export_model.py     # Model export utilities
â”‚
â””â”€â”€ README_TRAINING_PIPELINE.md  # This file
```

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install torch torchvision scikit-learn pandas numpy pillow pyyaml tqdm requests
```

**Optional dependencies:**
```bash
# For experiment tracking
pip install wandb

# For model export
pip install onnx onnxruntime coremltools

# For web scraping tiles
pip install selenium
```

### 2. Prepare Your Data

Your `data/tags.csv` should have these columns:

| Column | Type | Description | Example |
|--------|------|-------------|---------|
| `image_path` | string | Path to image file | `tile_34.0522_-118.2437.png` |
| `lat` | float | Latitude | `34.0522` |
| `lon` | float | Longitude | `-118.2437` |
| `type` | string | Tag type (label) | `ramp`, `elevator` |
| `source` | string | Data source | `user`, `osm`, `model` |

### 3. Generate Map Tiles (Optional)

If you don't have images yet:

```bash
# Generate tiles from your CSV
cd scripts
python generate_tiles.py --csv ../data/tags.csv --zoom 18

# Single tile example
python generate_tiles.py --lat 34.0522 --lon -118.2437 --zoom 18

# Use Mapbox (requires API token)
python generate_tiles.py --csv ../data/tags.csv --provider mapbox --token YOUR_TOKEN
```

### 4. Preprocess Data

```bash
cd data
python preprocess.py --input tags.csv
```

This creates:
- `tags_train.csv`, `tags_val.csv`, `tags_test.csv` (stratified splits)
- `preprocessing_metadata.json` (normalization parameters, class info)

### 5. Train Model

**Basic training (original baseline):**
```bash
cd models/baseline
python train.py
```

**Advanced training with transfer learning:**
```bash
cd scripts
python train_pipeline.py --config ../models/baseline/config.yaml --experiment-name "resnet18-v1"
```

**With mixed precision training (faster on modern GPUs):**
```bash
python train_pipeline.py --config ../models/baseline/config.yaml --amp
```

**With W&B experiment tracking:**
```bash
python train_pipeline.py --config ../models/baseline/config.yaml --wandb
```

### 6. Evaluate Model

```bash
cd models/baseline
python evaluate.py --checkpoint checkpoints/best_model.pth --split test
```

### 7. Export for Deployment

```bash
cd scripts
python export_model.py --checkpoint ../models/baseline/checkpoints/best_model.pth --format all
```

---

## âš™ï¸ Configuration

Edit `models/baseline/config.yaml`:

### Model Architecture

```yaml
model:
  backbone: 'custom'  # Options: custom, resnet18, resnet34, resnet50,
                      # efficientnet_b0, efficientnet_b1,
                      # mobilenet_v3_small, mobilenet_v3_large
  
  pretrained: true    # Use ImageNet pretrained weights
  freeze_layers: 0    # Freeze first N layers (0 = train all)
  
  # Custom CNN settings (when backbone='custom')
  cnn_channels: [32, 64, 128]
  cnn_dropout: 0.3
  
  # Metadata encoder
  metadata_hidden: 64
  
  # Fusion layer
  fusion_hidden: 256
  fusion_dropout: 0.3
  classifier_dropout: 0.3
  
  num_classes: 5
  image_size: 224
```

### Training Hyperparameters

```yaml
training:
  num_epochs: 50
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 0.0001
  
  optimizer: 'adamw'  # adam, adamw, sgd
  
  scheduler: 'cosine'  # step, cosine, plateau, none
  # For step scheduler:
  step_lr_step_size: 20
  step_lr_gamma: 0.1
  # For plateau scheduler:
  plateau_patience: 5
  plateau_factor: 0.5
  
  grad_clip: 1.0
  grad_accumulation_steps: 1  # Effective batch = batch_size * grad_accumulation_steps
  
  early_stopping_patience: 10
```

### Data Augmentation

```yaml
augmentation:
  enabled: true
  random_horizontal_flip: 0.5
  random_rotation: 15
  random_crop_scale: [0.8, 1.0]
  color_jitter_brightness: 0.2
  color_jitter_contrast: 0.2
```

---

## ğŸ—ï¸ Model Architectures

### 1. Custom CNN Baseline (~500K params)
```python
# Lightweight custom architecture
# Good for: Quick experiments, limited data
python train_pipeline.py --config config.yaml
# (config.yaml: backbone: 'custom')
```

### 2. ResNet18 Transfer Learning (~11M params)
```python
# Strong general-purpose model
# Good for: Production use, balanced accuracy/speed
python train_pipeline.py --config config_resnet18.yaml
# (config.yaml: backbone: 'resnet18', pretrained: true)
```

### 3. EfficientNet-B0 (~5M params)
```python
# Efficient architecture with excellent accuracy/params ratio
# Good for: Mobile deployment, edge devices
python train_pipeline.py --config config_efficientnet.yaml
# (config.yaml: backbone: 'efficientnet_b0', pretrained: true)
```

### 4. MobileNetV3-Small (~2.5M params)
```python
# Ultra-lightweight for mobile/embedded
# Good for: Real-time mobile inference
python train_pipeline.py --config config_mobilenet.yaml
# (config.yaml: backbone: 'mobilenet_v3_small', pretrained: true)
```

---

## ğŸ“Š Monitoring Training

### Training Logs

Check `models/baseline/logs/` for:
- `training_log_YYYYMMDD_HHMMSS.json` - Full training history
- `training_history_experiment_name.json` - Advanced pipeline history

### Checkpoints

`models/baseline/checkpoints/`:
- `best_model.pth` - Best validation accuracy
- `checkpoint_epoch_N.pth` - Per-epoch checkpoints

### Evaluation Results

`models/baseline/errors/`:
- `confusion_matrix_test_YYYYMMDD_HHMMSS.png`
- `metrics_test_YYYYMMDD_HHMMSS.json`
- `error_analysis_test_YYYYMMDD_HHMMSS.json`
- `images_test/` - Misclassified samples

### Weights & Biases

If using `--wandb`:
1. Login: `wandb login`
2. View experiments at https://wandb.ai/

---

## ğŸ“ Advanced Usage

### Fine-tuning Pretrained Models

**Freeze early layers, train only classifier:**
```yaml
model:
  backbone: 'resnet18'
  pretrained: true
  freeze_layers: 6  # Freeze first 6 layers
training:
  learning_rate: 0.0001  # Lower LR for fine-tuning
```

### Mixed Precision Training

**2x faster on modern GPUs, 50% less memory:**
```bash
python train_pipeline.py --config config.yaml --amp
```

### Gradient Accumulation

**Simulate larger batch sizes on limited GPU memory:**
```yaml
training:
  batch_size: 8
  grad_accumulation_steps: 4  # Effective batch size = 32
```

### Learning Rate Scheduling

**Cosine annealing (recommended for transfer learning):**
```yaml
training:
  scheduler: 'cosine'
  num_epochs: 50
```

**ReduceLROnPlateau (adaptive):**
```yaml
training:
  scheduler: 'plateau'
  plateau_patience: 5
  plateau_factor: 0.5
```

### Resume Training

```bash
python train_pipeline.py --config config.yaml --resume checkpoints/checkpoint_epoch_25.pth
```

---

## ğŸ”§ Troubleshooting

### Out of Memory (OOM) Errors

1. Reduce batch size in `config.yaml`
2. Enable mixed precision: `--amp`
3. Use gradient accumulation
4. Use smaller model (MobileNet instead of ResNet)

### Poor Convergence

1. Check data quality and preprocessing
2. Increase learning rate (try 0.001 â†’ 0.01)
3. Adjust augmentation (might be too aggressive)
4. Verify class balance in splits
5. Try different optimizer (AdamW often works better)

### Overfitting

1. Increase dropout rates
2. Enable/increase data augmentation
3. Use weight decay: `weight_decay: 0.0001`
4. More training data (collect more samples)
5. Early stopping (already enabled by default)

### Slow Training

1. Enable mixed precision: `--amp`
2. Increase batch size if memory allows
3. Reduce image size: `image_size: 192` (instead of 224)
4. Use smaller model
5. Enable pin_memory: `pin_memory: true`

---

## ğŸ“ˆ Performance Benchmarks

Tested on synthetic data (100 samples, 5 epochs):

| Model | Params | Train Time | Val Acc | Memory |
|-------|--------|------------|---------|--------|
| Custom CNN | 500K | ~5 min | 40% | 1.2 GB |
| ResNet18 | 11M | ~8 min | - | 2.5 GB |
| EfficientNet-B0 | 5M | ~10 min | - | 2.0 GB |
| MobileNetV3-Small | 2.5M | ~6 min | - | 1.5 GB |

*On real datasets (500+ samples, 50 epochs), expect 80-95% accuracy.*

---

## ğŸš¢ Deployment

### ONNX Export (Recommended)

```bash
python export_model.py --checkpoint checkpoints/best_model.pth --format onnx
```

**Inference with ONNX Runtime:**
```python
import onnxruntime as ort
import numpy as np

session = ort.InferenceSession("exports/best_model.onnx")
inputs = {
    'image': image_array,  # [1, 3, 224, 224]
    'lat': np.array([34.0522]),
    'lon': np.array([-118.2437]),
    'source': np.array([[1.0, 0.0, 0.0]])  # one-hot
}
outputs = session.run(None, inputs)
logits = outputs[0]
```

### TorchScript Export

```bash
python export_model.py --checkpoint checkpoints/best_model.pth --format torchscript
```

### Mobile Deployment (iOS)

```bash
python export_model.py --checkpoint checkpoints/best_model.pth --format coreml
```

### Model Quantization

**Reduce model size by 4x with minimal accuracy loss:**
```bash
python export_model.py --checkpoint checkpoints/best_model.pth --format onnx --quantize
```

---

## ğŸ“š Additional Resources

- **YOLOv5 Integration**: See `yolov5/` for object detection
- **Frontend Integration**: See `frontend/src/` for React app
- **Baseline Model Docs**: See `models/baseline/README.md`
- **API Server**: See `backend/main.py`

---

## ğŸ¤ Contributing

When adding new features:
1. Update this README
2. Add configuration options to `config.yaml`
3. Write tests
4. Document in code comments

---

## ğŸ“ License

See LICENSE file.

---

## âœ¨ Tips for Production

1. **Collect Quality Data**: 500+ diverse samples per class minimum
2. **Balance Classes**: Use class weights or oversample minority classes
3. **Validate Geographically**: Test on different cities/regions
4. **Monitor Drift**: Retrain periodically with new user-submitted tags
5. **A/B Test Models**: Compare multiple model versions in production
6. **Cache Predictions**: Save predictions for frequently accessed locations
7. **Ensemble Models**: Combine multiple models for better accuracy

---

**Need help?** Check existing issues or create a new one.

**Happy Training! ğŸš€**
